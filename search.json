[
  {
    "objectID": "log-reg.html",
    "href": "log-reg.html",
    "title": "Logistisk regression",
    "section": "",
    "text": "I det følgende ses på logistisk regression. Måske har du allerede hørt begrebet logistisk regression i gymnasieundervisningen i forbindelse med logistisk vækst. Dette er en anden type af logistisk regression end den som behandles i denne note. Senere vil vi dog se eksempler hvor der alligevel kan laves en sammenhæng med logistisk vækst.\nLogistisk regression, i den betydning vi kigger på i denne note, bruges, når man gerne vil modellere hvordan en sandsynlighed afhænger af en anden variabel. Som et eksempel forestiller vi os, at vi er interesserede i at undersøge sammenhængen mellem (systolisk) blodtryk og risikoen for hjerte-kar-sygdom.\nVi vil kigge på et datasæt bestående af 2000 mennesker, som har fået målt deres blodtryk. Desuden har de fået undersøgt, om de lider af hjertekarsygdom. Datasættet er fiktivt, men det er lavet til at ligne virkelige data1. Vi kalder blodtrykket for \\(x\\), mens vi lader \\(y\\) være en variabel, der er \\(1\\) hvis personen lider af hjertekarsygdom og \\(0\\) ellers. På figuren nedenfor har vi tegnet samhørende \\(x\\)- og \\(y\\)-værdier ind i et koordinatsystem for de første 200 personer i datasættet.\n1 De fleste mennesker har et systolisk blodtryk mellem 100 og 180 mmHg. I datasættet har vi genereret en masse mennesker med meget højt eller lavt blodtryk for illustrationens skyld.\n\n\n\n\n\n\n\n\nHvordan skal man beskrive sammenhængen mellem \\(x\\) og \\(y\\)? Det ser ud til at der blandt folk med meget lavt blodtryk er flest raske, mens der for folk med meget højt blodtryk er flest syge, men ved de fleste blodtryksværdier ser der ud til at være både syge og raske. I stedet for at se direkte på sammenhængen mellem \\(x\\) og \\(y\\) vil vi derfor se på hvordan sandsynligheden for hjerte-kar-sygdom (\\(y=1\\)) afhænger af blodtrykkket. Vi vil betragte denne sandsynlighed som en funktion \\(p(x)\\) som afhænger af blodtrykket \\(x\\). Vi skal se på hvordan man kan bestemme denne funktion.\nFor at få en idé om, hvordan \\(p(x)\\) kunne se ud, kigger vi datasættet fra før. Vi inddeler nu blodtrykket i intervaller af længde 25.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlodtryk\n]75,100]\n]100,125]\n]125,150]\n]150,175]\n]175,200]\n]200,225]\n]225,250]\n]250,275]\n]275,300]\n\n\n\n\nRask\n173\n194\n145\n156\n98\n57\n47\n25\n19\n\n\nSyg\n24\n42\n62\n100\n132\n135\n178\n203\n210\n\n\n\nFor hvert interval beregnes andelen af patienterne, der lider af hjerte-kar-sygdom som estimat for sandsynligheden for hjerte-kar-sygdom i den gruppe. F.eks. er der 236 personer med et blodtryk i intervallet \\(]100,125]\\). Heraf er 42 syge. Andelen af syge i denne gruppe er derfor \\[\n\\frac{42}{236} \\approx 0.178.\n\\] Der laves et plot hvor der for hver blodtryksinterval laves et punkt hvor \\(x\\)-værdien er midtpunktet for blodtryks- intervallet og \\(y\\) er den estimeret sandsynlighed ved intervallet.\n\n\n\n\n\n\n\n\n\nUmiddelbart kunne det være fristende at lave lineær regression. Vi forestiller os altså en forskrift \\[\n    p(x) = ax + b.\n\\] Hvis vi indtegner den bedste rette linje i plottet, får vi nedenstående:\n\n\n\n\n\n\n\n\n\nDer er et problem her: En sandsynlighed ligger altid mellem 0 og 1, men regressionslinjen ovenfor skærer \\(x\\)-aksen ved blodtryksværdier omkring 80. Det betyder, at sandsynligheden er negativ for blodtryk under 80. Tilsvarende får vi sandsynligheder, der er større end 1 ved blodtryk over 300. Det giver selvfølgelig ikke mening.\nHvis vi kigger på figur (ref) igen, ser sammenhængen da heller ikke lineær ud, men snarere S-formet. Vi kunne altså forestille os at grafen for \\(p\\) ser ud som indtegnet nedenfor:"
  },
  {
    "objectID": "log-reg.html#logistisk-regression",
    "href": "log-reg.html#logistisk-regression",
    "title": "Logistisk regression",
    "section": "",
    "text": "I det følgende ses på logistisk regression. Måske har du allerede hørt begrebet logistisk regression i gymnasieundervisningen i forbindelse med logistisk vækst. Dette er en anden type af logistisk regression end den som behandles i denne note. Senere vil vi dog se eksempler hvor der alligevel kan laves en sammenhæng med logistisk vækst.\nLogistisk regression, i den betydning vi kigger på i denne note, bruges, når man gerne vil modellere hvordan en sandsynlighed afhænger af en anden variabel. Som et eksempel forestiller vi os, at vi er interesserede i at undersøge sammenhængen mellem (systolisk) blodtryk og risikoen for hjerte-kar-sygdom.\nVi vil kigge på et datasæt bestående af 2000 mennesker, som har fået målt deres blodtryk. Desuden har de fået undersøgt, om de lider af hjertekarsygdom. Datasættet er fiktivt, men det er lavet til at ligne virkelige data1. Vi kalder blodtrykket for \\(x\\), mens vi lader \\(y\\) være en variabel, der er \\(1\\) hvis personen lider af hjertekarsygdom og \\(0\\) ellers. På figuren nedenfor har vi tegnet samhørende \\(x\\)- og \\(y\\)-værdier ind i et koordinatsystem for de første 200 personer i datasættet.\n1 De fleste mennesker har et systolisk blodtryk mellem 100 og 180 mmHg. I datasættet har vi genereret en masse mennesker med meget højt eller lavt blodtryk for illustrationens skyld.\n\n\n\n\n\n\n\n\nHvordan skal man beskrive sammenhængen mellem \\(x\\) og \\(y\\)? Det ser ud til at der blandt folk med meget lavt blodtryk er flest raske, mens der for folk med meget højt blodtryk er flest syge, men ved de fleste blodtryksværdier ser der ud til at være både syge og raske. I stedet for at se direkte på sammenhængen mellem \\(x\\) og \\(y\\) vil vi derfor se på hvordan sandsynligheden for hjerte-kar-sygdom (\\(y=1\\)) afhænger af blodtrykkket. Vi vil betragte denne sandsynlighed som en funktion \\(p(x)\\) som afhænger af blodtrykket \\(x\\). Vi skal se på hvordan man kan bestemme denne funktion.\nFor at få en idé om, hvordan \\(p(x)\\) kunne se ud, kigger vi datasættet fra før. Vi inddeler nu blodtrykket i intervaller af længde 25.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlodtryk\n]75,100]\n]100,125]\n]125,150]\n]150,175]\n]175,200]\n]200,225]\n]225,250]\n]250,275]\n]275,300]\n\n\n\n\nRask\n173\n194\n145\n156\n98\n57\n47\n25\n19\n\n\nSyg\n24\n42\n62\n100\n132\n135\n178\n203\n210\n\n\n\nFor hvert interval beregnes andelen af patienterne, der lider af hjerte-kar-sygdom som estimat for sandsynligheden for hjerte-kar-sygdom i den gruppe. F.eks. er der 236 personer med et blodtryk i intervallet \\(]100,125]\\). Heraf er 42 syge. Andelen af syge i denne gruppe er derfor \\[\n\\frac{42}{236} \\approx 0.178.\n\\] Der laves et plot hvor der for hver blodtryksinterval laves et punkt hvor \\(x\\)-værdien er midtpunktet for blodtryks- intervallet og \\(y\\) er den estimeret sandsynlighed ved intervallet.\n\n\n\n\n\n\n\n\n\nUmiddelbart kunne det være fristende at lave lineær regression. Vi forestiller os altså en forskrift \\[\n    p(x) = ax + b.\n\\] Hvis vi indtegner den bedste rette linje i plottet, får vi nedenstående:\n\n\n\n\n\n\n\n\n\nDer er et problem her: En sandsynlighed ligger altid mellem 0 og 1, men regressionslinjen ovenfor skærer \\(x\\)-aksen ved blodtryksværdier omkring 80. Det betyder, at sandsynligheden er negativ for blodtryk under 80. Tilsvarende får vi sandsynligheder, der er større end 1 ved blodtryk over 300. Det giver selvfølgelig ikke mening.\nHvis vi kigger på figur (ref) igen, ser sammenhængen da heller ikke lineær ud, men snarere S-formet. Vi kunne altså forestille os at grafen for \\(p\\) ser ud som indtegnet nedenfor:"
  },
  {
    "objectID": "log-reg.html#odds",
    "href": "log-reg.html#odds",
    "title": "Logistisk regression",
    "section": "Odds",
    "text": "Odds\nFor at komme nærmere hvordan funktionsforskriften for \\(p\\) skal se ud, kigger vi på oddsene for sygdom i stedet for sandsynligheden2. Oddsene \\(O\\) for en hændelse er defineret som sandsynligheden for hændelsen \\(p\\) divideret med sandsynligheden for komplementærhændelsen, som er \\(1-p\\). Altså \\[\n    O=\\frac{p}{1-p}\n\\] Odds måler således, hvor mange gange mere sandsynlig hændelsen er i forhold til komplementærhændelsen. Hvis fx sandsynligheden for hjerte-kar-sygdom er \\(p=\\frac{4}{5}\\) så er odds for sygdom \\[\n    O=\\frac{\\frac{4}{5}}{\\frac{1}{5}} = 4.\n\\] Det er altså fire gange så sandsynligt at være syg som at være rask.\n2 Du kender måske begrebet odds fra sportsgambling. Det er dog en anden betydning af ordet end det vi bruger her. Inden for gambling angiver odds, hvor mange gange man får pengene igen, hvis en bestemt hændelse indtræffer(fx. et bestemt hold vinder). Gambling odds er naturligvis udregnet ud fra de sandsynlighedsteoretiske odds for hændelsen, men er altid justeret for at sikre at bookmakeren vinder i det lange løb.For at få en lidt bedre fornemmelse for, hvordan odds fungerer, kan vi lave en tabel, der viser odds svarende til forskellige værdier af \\(p\\):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(p\\)\n\\(\\frac{1}{5}\\)\n\\(\\frac{1}{4}\\)\n\\(\\frac{1}{3}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{2}{3}\\)\n\\(\\frac{3}{4}\\)\n\\(\\frac{4}{5}\\)\n\n\n\n\n\\(O\\)\n\\(\\frac{1}{4}\\)\n\\(\\frac{1}{3}\\)\n\\(\\frac{2}{3}\\)\n1\n2\n3\n4\n\n\n\nFunktionen, der omdanner sandsynligheder til odds har forskriften \\[\nf(p) = \\frac{p}{1-p},\n\\] hvor \\(p\\) kan ligge mellem 0 og 1. Grafen for \\(f\\) er tegnet nedenfor.\n\n\n\n\n\n\n\n\n\nVi ser at \\(f\\) altid er positiv, da både tæller og nævner er positive. Når \\(p\\) nærmer sig \\(0\\), nærmer tælleren sig \\(0\\) mens nævneren nærmer sig \\(1\\), så \\(f(p)\\) går mod \\(0\\). Når \\(p\\) nærmer sig \\(1\\), nærmer tælleren sig \\(1\\) og nævneren nærmer sig \\(0\\), så hele brøken \\(f(p)\\) går mod uendelig. Værdimængden for \\(f\\) består derfor af alle de positive reelle tal.\nI vores dataeksempel, hvor sandsynligheden for hjerte-kar-sygdom er en funktion \\(p(x)\\), bliver oddsene for hjerte-kar-sygdom også en funktion af \\(x\\) \\[\nO(x) = \\frac{p(x)}{1-p(x)}.\n\\] Nedenfor vises dataeksemplet fra før, men hvor vi nu har oddsene \\(O(x)\\) på \\(y\\)-aksen.\n\n\n\n\n\n\n\n\n\nVi ser at oddsene for sygdom stiger med blodtrykket. Kigger vi på grafen, ser tendensen ikke lineær ud. Det kunne derimod ligne en eksponentiel vækst. For at bekræfte dette, laver vi samme plot, men nu med den naturlige logaritme til oddsene \\(\\ln (O(x))\\) på \\(y\\)-aksen.\n\n\n\n\n\n\n\n\n\nDer ser nu ud til at være en lineær sammenhæng! Det kunne altså tyde på, at log-oddsene afhænger lineært af \\(x\\). Det leder os frem til følgende model for log-oddsene: \\[\n\\ln (O(x)) = ax  + b.\n\\] Denne model kaldes den logistiske regressionsmodel. Virkelige data følger ofte en logistisk regressionsmodel.\nMed denne model og ved blot at se på grafen kunne man fristes til at benytte lineær regression til at finde \\(a\\) og \\(b\\). Her er det dog vigtigt at bemærke at et punkt fra grafen egentligt er kombinationen af data fra flere observationer som ikke engang hvade samme \\(x\\)-værdi. Antal af observationer som hvert punkt er lavet ud fra er desuden heller ikke ens."
  },
  {
    "objectID": "log-reg.html#logit-funktionen-og-den-logistiske-funktion",
    "href": "log-reg.html#logit-funktionen-og-den-logistiske-funktion",
    "title": "Logistisk regression",
    "section": "Logit-funktionen og den logistiske funktion",
    "text": "Logit-funktionen og den logistiske funktion\nNår vi tager den naturlige logaritme til oddsene får vi \\[\n\\ln (O) = \\ln\\left(\\frac{p}{1-p}\\right).\n\\] Funktionen på højresiden kaldes \\(\\text{logit}\\), altså \\[\n\\text{logit}(p) = \\ln\\left(\\frac{p}{1-p}\\right).\n\\] Definitionsmængden for \\(\\text{logit}\\)-funktionen er det åbne interval \\(]0,1[\\). Vi fandt tidligere, at værdimængden for oddsene består af alle de positive reelle tal. Dette er netop definitionsmængden for \\(\\ln\\). Værdimængden for \\(\\text{logit}\\) bliver derfor den samme som for \\(\\ln\\), nemlig alle de reelle tal. Grafen for \\(\\text{logit}\\) er vist nedenfor.\n\n\n\n\n\n\n\n\n\nVi vil nu finde den inverse funktion til \\(\\text{logit}\\). Antag at \\[\ny = \\text{logit(p)} = \\ln\\left( \\frac{p}{1-p} \\right).\n\\] Vi vil prøve at udtrykke \\(p\\) som funktion af \\(y\\). Vi tager først eksponentialfunktionen på begge sider af udtrykket og får \\[\ne^y =  \\frac{p}{1-p}\n\\] Så ganger vi med \\((1-p)\\) på begge sider. \\[\ne^y(1-p) =p\n\\] Hvis parentesen ophæves får vi \\[e^y - p\\cdot e^y =p\\]\nVi kan så lægge \\(p\\cdot e^y\\) til på begge sider og sætte \\(p\\) uden for parantes \\[\ne^y = p \\cdot e^y+p  \\\\\ne^y = p\\cdot (e^y+1)\n\\] Endelig kan vi isolere \\(p\\) og få \\[\n\\frac{e^y}{e^y+1} =p\n\\] Her er \\(p\\) egentlig isoleret men vi kan forkorte brøken med \\(e^y\\) for at få et andet udtryk for \\(p\\). \\[\np=\\frac{\\frac{e^y}{e^y}}{\\frac{e^y+1}{e^y}}=\\frac{\\frac{e^y}{e^y}}{\\frac{e^y}{e^y}+\\frac{1}{e^y}}    =\\frac{1}{1+e^{-y}} .\n\\]\nSammenlagt har vi vist, at den inverse funktion til logit er den standard logistiske funktion (også nogle gange kaldet sigmoide-funktionen) NOTE: eller sigmoid? \\[\nf(y) = \\frac{1}{1+e^{-y}}.\n\\] Grafen for den standard logistiske funktion er indtegnet nedenfor. Vi ser at grafen har en karakteristisk S-form, som vokser fra \\(0\\) mod \\(1\\).\n\n\n\n\n\n\n\n\n\nHvis man har en funktion \\(f\\) kan væksthastigheden øges med en faktor \\(a\\) ved at se på \\(f(ax)\\). Hvis man derimod ønsker at forskyde grafen med \\(k\\) i \\(x\\)-aksens retning kan det gøres ved at se på \\(f(x-k)\\). Hvis man kombinere disse, og øger væksthastigheden med en faktor \\(a\\), og derefter forskyder grafen med \\(k=\\frac{-b}{a}\\) i \\(x\\)-aksens retning fås istedet funktionen \\[f(a\\cdot (x-(\\frac{-b}{a})))=f(ax+b).\\]\nHvis man gør dette for den standard logistiske funktion, får man den generelle logistiske funktion\n\\[\nf(ax+b) =\\frac{e^{ax+b}}{1+e^{ax+b}}= \\frac{1}{1+e^{-(ax+b)}}.\n\\]\nSammenlignet med den standard logistiske funktion får man altså en \\(S\\)-formet kurve, der vokser \\(a\\) gange så hurtigt og er forskudt med \\(\\frac{-b}{a}\\). Fx får man for \\(a=2\\) og \\(b=-5\\):\n\n\n\n\n\n\n\n\n\nDet var en logistisk funktion af denne type, der blev brugt til at lave den S-formede kurve i Figur ?.\nHer laves et datasæt hvor du selv kan forsøge at tilpasse modellen. Vigtigt at hjælpe læseren med lidt info, med at det jo ikke er meningen at grafen skal gå gennem punkterne, men istedet skal indikere hvor stor sandsynlighed der er for ….. lige ved det sted. Desuden bør man kunne få vist den bedste model."
  },
  {
    "objectID": "log-reg.html#den-logistiske-regressionsmodel",
    "href": "log-reg.html#den-logistiske-regressionsmodel",
    "title": "Logistisk regression",
    "section": "Den logistiske regressionsmodel",
    "text": "Den logistiske regressionsmodel\nVi vender nu tilbage til den logistiske regressionsmodel. Husk på, at da \\(\\ln (O(x)) = \\text{logit} (p(x))\\), siger modellen \\[\n\\ln (O(x)) = \\text{logit}(p(x)) = ax  + b.\n\\] Da værdimængden for \\(\\text{logit}\\) var alle de reelle tal, giver det mening at modellere \\(\\text{logit}(p(x))\\) med en lineær funktion.\nHvis vi gerne vil have et udtryk for oddsene, kan vi tage eksponentialfunktionen på begge sider \\[\nO(x) = e^{ax + b} = e^b \\cdot e^{ax}=e^b \\cdot (e^{a})^x\n.\\]\nHvis \\(e^b\\) kaldes \\(b_{ny}\\) og \\(e^{a}\\) kaldes \\(a_{ny}\\), ses at \\(O(x)=b_{ny}\\cdot a_{ny}^x\\) er en eksponentiel funktion med fremskrivningsfaktor \\(a_{ny}=e^a\\). Derved vil %-delen som Odds for sygdom stiger med være \\(r=e^a-1\\) hver gang blodtrykket stiger med \\(1\\) mmHg.\nI forbindelse med logistisk regression kaldes \\(e^a\\) også for odds-ratioen. For at forstå hvorfor, kan vi forestille os to patienter, en med blodtryk \\(x_1\\) og en med blodtryk \\(x_2\\). De har dermed oddsene \\[\nO(x_1) = e^b \\cdot e^{ax_1}\\\\\nO(x_2) = e^b \\cdot e^{ax_2}.\n\\] Lad os se på forholdet (ratioen) mellem de to personers odds: \\[\n\\frac{O(x_1)}{O(x_2)} = \\frac{e^b \\cdot e^{ax_1}}{ e^b \\cdot e^{ax_2}} = \\frac{e^{ax_1}}{e^{ax_2}} = e^{ax_1 - ax_2} = e^{a(x_1 - x_2)} = (e^{a} )^{x_1-x_2}.\n\\] Forholdet mellem oddsene afhænger altså kun af forskellen \\(x_1 - x_2\\) mellem de to personers blodtryk. Hvis person 1 er har et blodtryk, der er 1mmHg højere end person 2, bliver forholdet (ratioen) mellem oddsene lige præcis \\(e^a\\). Sagt på en anden måde: Odds for sygdom stiger med en faktor \\(e^a\\) hver gang blodtrykket stiger med 1 mmHg.\nOdds kan være svære at forstå intuitivt. Vi vil derfor prøve at finde tilbage til et udtryk for sandsynligheden for sygdom \\(p(x)\\). Vi havde modellen \\[\n\\text{logit}(p(x) )  = ax  + b.\n\\] Bruger vi den inverse funktion (som vi fandt var den logistiske funktion) på begge sider, får vi \\[\np(x)  = \\frac{ e^{ax  + b}}{1 + e^{ax  + b}}.\n\\] eller \\[\np(x)  = \\frac{1}{1 + e^{-(ax  + b)}}.\n\\]\nVi får altså et logistisk funktionsudtryk for \\(p\\), deraf navnet “den logistiske regressionsmodel”. Nu skal vi bare finde ud af hvordan \\(a\\) og \\(b\\) bestemmes ud fra et datasæt, dette er dog ikke helt simpelt.\nTidligere definerede vi egentlig \\(O(x)\\) ud fra \\(p(x)\\), men udfra formlerne \\[O(x) = e^{ax + b}\\quad \\text{og} \\quad p(x)  = \\frac{ e^{ax  + b}}{1 + e^{ax  + b}}\\] ses også let hvordan \\(p(x)\\) findes ud fra \\(O(x)\\) ved \\[p(x)=\\frac{O(x)}{1+O(x)}.\\]\nLad os se på hvordan man selv kan få en ide om estimater for \\(a\\) og \\(b\\) ud fra de oprindelige grafer.\nVi bruger her at \\[\nax+b = \\text{logit(p)} = \\ln\\left( \\frac{p}{1-p} \\right).\n\\] og se på hvor midtpunktet er og hvor hurtigt funktionen vokser. Ved midtpunktet er \\(p=50\\%=0,5\\). Derved er \\[ax+b =\\ln\\left( \\frac{0.5}{1-0.5} \\right) =ln(1)=0.\\] Og ved at isolere \\(b\\) fås at \\(x=\\frac{-b}{a}\\) Hvis vi ønsker at se på hvor meget \\(x\\)-værdien skal før \\(p\\) ændres fra f.eks. 20% til 80% (note med det er symmetrisk sandsynlighed) kan det gøres på følgende måde. Lad først \\(x_{20\\%}\\) være \\(x\\)-værdien svarende til \\(p=20\\%=0,2\\) og tilsvarende ved \\(p=80\\%=0,8\\). Vi ønkser nu at finde \\[a\\cdot x_{80\\%}+b-(a\\cdot x_{20\\%}-b)=\\ln\\left( \\frac{0.8}{1-0.8} \\right)-\\ln\\left( \\frac{0.2}{1-0.2} \\right).\\] Hvis man ser på de to brøkker er de egentlig ens blot tæller og nævner er byttet om. Ved at benytte at \\(ln(a)-ln(b)=ln(\\frac{a}{b})\\) kan man vise at \\(ln(\\frac{a}{b})=-ln(\\frac{b}{a})\\). Ved at benytte dette og omskrive venstresiden fås\n\\[a\\cdot(x_{80\\%}-x_{20\\%})=\\ln\\left( \\frac{0.8}{1-0.8} \\right)-\\left(-\\ln\\left( \\frac{0.8}{1-0.8} \\right)\\right)=2\\cdot\\ln\\left( \\frac{0.8}{1-0.8} \\right).\\] Derved bliver \\[x_{80\\%}-x_{20\\%}=\\frac{2\\cdot\\ln\\left( \\frac{0.8}{1-0.8} \\right)}{a}=\\frac{2\\cdot logit(0,8)}{a}.\\] Her kan man selvfølgelig også bestemme \\(a\\) hvis man har en ide om hvor hurtig man går fra en sandsynlighed fra 20 % til 80 % ved\n\\[a=\\frac{2\\cdot\\ln\\left( \\frac{0.8}{1-0.8} \\right)}{x_{80\\%}-x_{20\\%}}=\\frac{2\\cdot logit(0,8)}{x_{80\\%}-x_{20\\%}}.\\]"
  },
  {
    "objectID": "log-reg.html#maksimum-likelihood-estimation",
    "href": "log-reg.html#maksimum-likelihood-estimation",
    "title": "Logistisk regression",
    "section": "Maksimum likelihood estimation",
    "text": "Maksimum likelihood estimation\nI den logistiske regressionsmodel indgår to ukendte parametre \\(a\\) og \\(b\\). Hvis vi har et datasæt, hvordan finder vi så de værdier af \\(a\\) og \\(b\\) der passer bedst til vores data? Som regel bruges maksimum likelihood metoden, som er en teknik, der stammer fra statistikken. Kort fortalt er idéen at vælge de parametre, der gør vores data så sandsynligt som muligt.\nLad os kalde punkterne i vores datasæt \\((x_i,y_i)\\), hvor \\(i=1,\\ldots,n\\) er en nummerering af datapunkterne. Her angiver \\(x_i\\) blodtrykket hos den \\(i\\)’te person, og \\(y_i\\) er en variabel, der antager værdien \\(1\\) hvis \\(i\\)’te person har hjerte-kar-sygdom og er \\(0\\) ellers, dvs. \\[\n    y_i=\n    \\begin{cases}\n        1,& \\text{ hvis $i$'te person har hjerte-kar-sygdom,}\\\\\n        0,& \\text{ hvis $i$'te person ikke har hjerte-kar-sygdom.}\n    \\end{cases}\n\\]\nFor hvert par \\((x_i,y_i)\\) kan vi nu forsøge at beregne sandsynligheden \\(p_i\\) for at \\(i\\)’te person faktisk har den sygsomsstatus \\(y_i\\) som vi observerer når vi ved at blodtrykket er \\(x_i\\). Hvis den \\(i\\)’te person er syg, dvs. \\(y_i=1\\), er \\[\np_i= p(x_i)  = \\frac{ e^{ax_i  + b}}{1 + e^{ax_i  + b}}.\n\\] Hvis patienten er rask, altså \\(y_i=0\\), er \\[\np_i=1-  p(x_i)  = 1- \\frac{ e^{ax_i  + b}}{1 + e^{ax_i  + b}} = \\frac{ 1 }{1 + e^{ax_i  + b}}.\n\\] Bemærk at \\(p_i\\) afhænger af de ukendte parametre \\(a\\) og \\(b\\). Vi kan altså opfatte \\(p_i\\) som en funktion \\(p_i(a,b)\\).\nNu kigger vi på den samlede sandsynlighed for at observere netop de værdier \\(y_1,\\ldots,y_n\\), som vi faktisk har observeret, når vi ved at patienternes blodtryk er givet ved \\(x_1,\\ldots,x_n\\). Til det formål antager vi, at personerne i datasættet er udvalgt uafhængigt af hinanden. (Afhængigheder kan fx opstå hvis mange af personerne er i familie med hinanden, går i klasse sammen eller bor i samme by. I så fald kan de have noget tilfælles, der gør at deres \\(y\\)-værdier er mere ens end ellers. Familiemedlemmer kan fx have samme arvelige tendens til hjerte-kar-sygdom. Som regel forsøger man at undgå sådanne afhængigheder når man indsamler data.)\nFor at komme videre, er vi nødt til at vide lidt om uafhængighed af hændelser: Husk på at to hændelser \\(A\\) og \\(B\\) er uafhængige hvis man kan finde sandsynligheden for fælleshændelsen \\(A\\cap B\\) (at \\(A\\) og \\(B\\) indtræffer på en gang) ved at gange de enkelte sandsynligheder sammen: \\[\n    P(A\\cap B) = P(A)\\cdot P(B).\n\\]\nUafhængighed af \\(n\\) hændelser \\(A_1,\\ldots,A_n\\) betyder tilsvarende at sandsynligheden for at alle \\(n\\) hændelser indtræffer på samme tid \\(A_1 \\cap A_2 \\cap \\dotsm \\cap A_n\\) kan findes som et produkt af sandsynlighederne for de enkelte hændelser: \\[\n    P(A_1 \\cap A_2 \\cap \\dotsm \\cap A_n) = P(A_1)\\cdot P(A_2) \\cdot \\dotsm \\cdot P(A_n).\n\\] (Desuden skal der gælde, at hver gang vi udtager \\(m\\) ud af de \\(n\\) hændelser, skal sandsynligheden for de \\(m\\) hændelser indtræffer samtidig kunne findes ved en tilsvarende produktformel, men dette skal vi ikke bruge i det følgende).\nFor at vende tilbage til vores data så lader vi \\(A_1\\) være hændelsen at første patient har sygdomsstatus \\(y_1\\), \\(A_2\\) være hændelsen at anden patient har sygdomsstatus \\(y_2\\) osv. Bemærk at \\(P(A_i)\\) er det samme som det vi tidligere kaldte \\(p_i(a,b)\\). Hændelsen at vi observerer alle de \\(y_1,\\ldots,y_n\\) som vi faktisk observerer på samme tid er fælleshændelsen \\(A_1 \\cap A_2 \\cap \\dotsm \\cap A_n\\). Da vi antog at de \\(n\\) personer er udvalgt uafhængigt af hinanden, kan vi bruge produktformlen: \\[\nP(A_1 \\cap A_2 \\cap \\dotsm \\cap A_n) = P(A_1) \\cdot \\dotsm \\cdot P(A_n) = p_1(a,b) \\cdot p_2(a,b)\\cdot \\dotsm \\cdot p_n(a,b).\n\\] Bemærk, at sandsynligheden for vores udfald \\(y_1,\\ldots,y_n\\) afhænger af \\(a\\) og \\(b\\). Den kan derfor betragtes som en funktion af to variable \\[\nL(a,b) = p_1(a,b) \\cdot p_2(a,b)\\cdot \\dotsm \\cdot p_n(a,b).\n\\] Denne funktion kaldes likelihoodfunktionen. Idéen med maksimum likelihood metoden er at vælge de værdier af \\(a\\) og \\(b\\), der gør sandsynligheden \\(L(a,b)\\) for det vi har observeret så stor som muligt. Vi søger altså de \\(a\\) og \\(b\\), der maksimerer funktionen \\(L(a,b)\\). Dette maksimum kan ikke udregnes eksakt. I stedet kan man bruge numeriske metoder, fx gradient descent, som I kan læse mere om her… link til note. Disse optimeringsmetoder vil gøre brug af de partiel afledte, og sidst i dokumnetet gennemgås flere detaljer til dette.\nFinder man \\(a\\) og \\(b\\) ved hjælp af maksimum likelihood metoden i vores dataeksempel, fås funktionen \\[\n    p(x) = e^{0.0230 x -4.07}.\n\\]\n\\[Tjek op på om det er 0,023 eller 0,03\\]\nGrafen for \\(p\\) er vist nedenfor. Vi har en odds-ratio på \\(e^{0.023} \\approx 1,0233\\). Odds for hjerte-kar-sygdom stiger derfor med en faktor 1,0233 (altså 2,33%) for hver gang blodtrykket stiger med \\(1\\) mmHg."
  },
  {
    "objectID": "log-reg.html#prædiktion",
    "href": "log-reg.html#prædiktion",
    "title": "Logistisk regression",
    "section": "Prædiktion",
    "text": "Prædiktion\nLad os nu sige, at vi har estimeret \\(a\\) og \\(b\\) ud fra et datasæt. Vi har altså fundet en model for risikoen for sygdom \\[\n    p(x) = \\frac{e^{ax+b}}{1+e^{ax+b}}.\n\\] Hvis vi så får en ny patient med blodtryk \\(x\\), kan vi prøve at bruge modellen til at forudsige (prædiktere) om patienten er syg eller ej. Vi kan beregne sandsynligheden \\(p(x)\\) for at patienten er syg ud fra vores model. Den mest oplagte prædiktionsregel er at prædiktere det mest sandsynlige:\n\nHvis \\(p(x)&gt;1/2\\): Patienten er syg.\nHvis \\(p(x)\\leq 1/2\\): Patienten er rask.\n\nI praksis kan der dog være et problem, hvis man gerne vil kunne forudsige en meget sjælden sygdom. I dette tilfælde vil det ofte være sådan at \\(p(x)\\leq 1/2\\) for alle patienter. Ingen ville blive diagnosticeret med sygdommen på denne måde - og så er prædiktionsalgoritmen jo ikke meget værd. Derfor vælger man ofte et lavere delepunkt end \\(p(x)=1/2\\). Dermed kommer man til at fejldiagnosticere en hel del patienter. Til gengæld får man fanget flere af dem, der faktisk er syge.\nHer på siden har vi flere eksempler på algoritmer, som vil kunne bruges til at prædiktere om patienter er syge eller raske, fx neurale netværk og Bayes klassifikation (flere?)3. Fordelen ved at bruge logistisk regression er, at man ikke bare får en prædiktion, men også en model for, hvordan sandsynligheden \\(p(x)\\) afhænger af variablen \\(x\\). Dermed opnår man en indsigt i, hvordan sammenhængen mellem fx blodtryk og hjerte-kar-sygdom er. Ved hjælp af odds-ratioer kan vi endda sætte tal på hvordan odds for sygdom ændrer sig når blodtrykket vokser. Dette er i modsætning til mange andre prædiktionsalgoritmer, der blot giver en prædiktion, uden at brugeren af algoritmen ved hvor den kommer fra. Inden for medicin er det ofte vigtigt at kende baggrunden for en given prædiktion, så man kan forholde sig kritisk til resultatet og rådgive patienten om hvordan man sænker risikoen for sygdom (fx med blodtrykssænkende medicin). Til gengæld har de mere avancerede algoritmer mulighed for at give en mere præcis prædiktion.\n3 Logistisk regression er i øvrigt et meget simpelt eksempel på et neuralt netværk."
  },
  {
    "objectID": "log-reg.html#multipel-logistisk-regression",
    "href": "log-reg.html#multipel-logistisk-regression",
    "title": "Logistisk regression",
    "section": "Multipel logistisk regression",
    "text": "Multipel logistisk regression\nI praksis er der selvfølgelig flere faktorer end blodtryk, der afgør ens risiko for hjerte-kar-sygdom. Fx stiger risikoen med alderen, ligesom rygning øger risikoen. Vi kan opstille en model, der inddrager alle tre variable på en gang. Lader vi \\(x_1\\) betegne blodtryk, \\(x_2\\) betegne alder, og \\(x_3\\) betegne antal cigaretter, man ryger pr. dag, kan man tilføje dem til formlen for log-odds ved \\[\n    \\ln O(x_1,x_2,x_3) = a_1x_1 + a_2x_2 +a_3x_3 + b,\n\\] dvs. \\[\n     O(x_1,x_2,x_3) = e^{a_1x_1 + a_2x_2 +a_3x_3 + b}\n\\] og \\[\n    p(x_1,x_2,x_3) = \\frac{e^{a_1x_1 + a_2x_2 +a_3x_3 + b}}{1+e^{a_1x_1 + a_2x_2 +a_3x_3 + b}}.\n\\]\nHvordan skal vi forstå denne model? Jo, lad os forestille os en patient med alder \\(x_1\\) og blodtryk \\(x_2\\), som ryger \\(x_3\\) cigaretter om dagen. Hvis vedkommende begynder at ryge \\(1\\) cigaret mere om dagen (og vi forestiller os at alder og blodtryk er uændret) så vil odds-ratioen være \\[\n    \\frac{O(x_1,x_2,x_3+1)}{O(x_1,x_2,x_3)} = \\frac{ e^{a_1x_1 + a_2x_2 +a_3(x_3+1) + b}}{e^{a_1x_1 + a_2x_2 +a_3x_3 + b}} =e^{a_3}.\n\\] Den ekstra daglige cigaret vil altså øge odds for sygdom med en faktor \\(e^{a_3}\\). Tilsvarende har \\(e^{a_1}\\) og \\(e^{a_2}\\) fortolkninger som odds-ratioer, når hhv. blodtryk og alder stiger med 1 mens alle andre variable fastholdes. Selv om modellen tager alle tre variable i betragtning, får vi altså mål for den individuelle effekt af hver af de tre variable.\nMaximum likelihood metoden kan igen benyttes til at estimere parametrene \\(a_1,a_2,a_3\\) og \\(b\\). Framingham ?????????? datasættet som vi så på tidligere indeholder alle de tre nævnte variable. Estimerer man parametrene, får man følgende \\[\n    O(x_1,x_2,x_3) = e^{0.02x_1 + 0.06x_2 + 0.02x_3 -6.77 }.\n\\] Odds for hjerte-kar-sygdom stiger således med en faktor \\(e^{0.02}\\approx 1,02\\) (altså med 2%) for hver cigaret man ryger om dagen."
  },
  {
    "objectID": "log-reg.html#anvendelser-af-logistisk-regression-til-andet",
    "href": "log-reg.html#anvendelser-af-logistisk-regression-til-andet",
    "title": "Logistisk regression",
    "section": "anvendelser af logistisk regression til andet",
    "text": "anvendelser af logistisk regression til andet\nPredektion af sygdom ud fra måling af stof, hvor det er naturligt at man har stof i krop, men højt indhold vil indikere en sygdom. Evt. blodsukker og diabetes. Undersøgelse af om en person tænkes at fortage køb i forretning ud fra viden om alder og indkomst."
  },
  {
    "objectID": "log-reg.html#sammenhæng-mellem-logistisk-regression-og-logistisk-vækst",
    "href": "log-reg.html#sammenhæng-mellem-logistisk-regression-og-logistisk-vækst",
    "title": "Logistisk regression",
    "section": "Sammenhæng mellem logistisk regression og logistisk vækst",
    "text": "Sammenhæng mellem logistisk regression og logistisk vækst\nDet er selvfølgelig oplagt at tænke på om der er en sammenhæng mellem logistisk regression og logistisk vækst, både ud fra navnet men også ud fra grafernes forløb.\nVed logistisk vækst har vi en funktion af typen \\[f(x)=\\frac{M}{1+c\\cdot e^{-M\\cdot a\\cdot x}}\\] Hvor \\(c\\) normalt er et positivt tal og \\(M\\) er en øvre grænse for \\(f(x)\\) og hvor \\[\\lim_{x\\to \\infty} f(x)=M.\\]\nFunktionen er desuden løsning til differentialligningen \\[y'=a\\cdot y\\cdot (M-y)\\] hvor \\(a&gt;0\\).\nLad os se på et eksempel hvor man ønsker at se på hvor hurtigt det går før en befolkning får immunitet mod en sygdom, og hvor vi med tiden regner med at alle bliver imune. For at beskrive dette ved logistik vækst vil man typisk lave et datasæt hvor man til givne tidspunkter ved hvor mange der er imune. Egentlig kræver det stort arbejde at få et sådan datasæt da det kræver information fra alle personer.\nI stedet kunne man for hver dag der går tage en test af en (eller flere) tilfældig person og se om personen er imun eller ikke er imun. Derved får man et datasæt med punkter \\((x,y)\\) hvor \\(x\\) er tid(dage) og \\(y\\) kunne være \\(0\\) svarende til ikke imun eller \\(1\\) svarende til imun. Dette datasæt er derved oplagt at undersøge med logistisk regression. Og derfra få en model af typen\n\\[{p(x)} =\\frac{1}{1+e^{-(a\\cdot x+b)}}=\\frac{1}{1+e^{-a\\cdot x-b}}.\\]\nHer ses selvfølgelig ikke på hvor mange der er imune men istedet sandsynligheden for at en tilfældig udvalgt er imun til tidspunktet \\(x\\).\nDet kan selvfølgelig være at man ønsker et bud på hvor mange der faktisk er imune blandt hele befolkningen med \\(M\\) personer. Hvis \\(f(x)\\) er antal imune efter \\(x\\) dage må det være oplagt at benytte modellen\n\\[f(x)=M\\cdot p(x)=\\frac{M}{1+e^{-a\\cdot x-b}}.\\] Ved \\(a\\) kan vi lige gange og dividere med \\(M\\) og kalde \\(a/M\\) for \\(a_{ny}\\). Derved er \\[f(x)=\\frac{M}{1+e^{-M\\cdot a_{ny}\\cdot x-b}}.\\] Ved at benytte potensregneregel får vi \\[f(x)=\\frac{M}{1+e^{-b}\\cdot e^{-M\\cdot a_{ny}\\cdot x}}.\\] Hvis vi kalder \\(e^{-b}\\) for \\(c\\) får vi \\[f(x)=\\frac{M}{1+c\\cdot e^{-M\\cdot a_{ny}\\cdot x}}.\\] Som netop svarer til funktionstypen hørende til logistisk vækst.\nDet er dog ikke ved alle eksempler at det er oplagt at lave denne kobling mellem de to emner, og det kræver desuden at \\(M\\) er kendt.\nAndre eksempler hvor man kunne lave sammen kobling kunne f.eks. være undersøgelse af hvor hurtigt folk skifter til et nyt system som Mitid eller andet som alle med tiden skal bruge."
  },
  {
    "objectID": "log-reg.html#bestemmelse-af-a-og-b-med-excel-solve-værktøj",
    "href": "log-reg.html#bestemmelse-af-a-og-b-med-excel-solve-værktøj",
    "title": "Logistisk regression",
    "section": "Bestemmelse af \\(a\\) og \\(b\\) med excel-solve-værktøj",
    "text": "Bestemmelse af \\(a\\) og \\(b\\) med excel-solve-værktøj\nMan kan benytte excel til at finde estimat for \\(a\\) og \\(b\\). Her skal man først og fremmest sørge for at man har aktiveret problemløser-værktøjet som gøres på følgende måde: Gå op under filer og vælg indstillinger. Derefter vælges tilføjelsesprogrammer. Nederst kan man vælge Excel-tilføjelsesprogrammer og trykke udfør. Til sidst kan man endelig tilføje problemløser-værktøjet fra en liste.\n\n\n\nIllustration af excel ark til bestemmelse af a og b samt brug af problemløser\n\n\nPå billedet ses hvordan man kan lave et lille regneark hvor man kan beregne de vigtige størrelser. Desuden der der vist med rød hvor man finder problemløser og hvad der skal justeres.\nNår man laver excel-arket er der lavet et par celler til de ukendte parametre \\(a\\) og \\(b\\), som egentlig bare kan sættes til 0 fra starten. Ved beregning i cellerne med \\(p(xi)\\) er det selvfølgelig vigtigt at disse celler benyttes (og fastlåsning af referencere med vil være smart, hvor man har $ foran både tal og bogstav ved reference).\nEfter beregning af \\(p(xi)\\) vil det være oplagt at benytte formel ???, og fra noget af det efterfølgende teori følger det at \\[ln(pi)={y_i}\\cdot ln(p(x_i))+(1-y_i)\\cdot ln(1-p(x_i)).\\] Til sidst skal man have fundet summen af alle \\(l(p_i)\\), da det netop giver \\(l(a,b)\\). Nu mangler man bare at benytte problemløseren til at sørge for at summen bliver maksimal ved at de to parametre \\(a\\) og \\(b\\) justeres."
  },
  {
    "objectID": "log-reg.html#ekstra-detaljer-til-optimering",
    "href": "log-reg.html#ekstra-detaljer-til-optimering",
    "title": "Logistisk regression",
    "section": "Ekstra detaljer til optimering",
    "text": "Ekstra detaljer til optimering\nFor at finde et maksimum eller minimum for en funktion af flere vairable vil det være oplagt at se på de partiel afledte ligesom hvis man finder stationære punkter for en funktion af to variable.\nVi havde \\[\nL(a,b) = p_1(a,b) \\cdot p_2(a,b)\\cdot \\dotsm \\cdot p_n(a,b).\n\\] Tidligere indså vi også at \\[\n    p_i(a,b) =\n    \\begin{cases}\n        p(x_i),& \\text{ hvis $y_i=1$,}\\\\\n        1-p(x_i),& \\text{ hvis $y_i=0$.}\n    \\end{cases}\n\\] Denne kan egentlig skrives på følgende måde: \\[p_i(a,b)=p(x_i)^{y_i}\\cdot (1-p(x_i))^{1-y_i}.\\]\nFor at se dette er det oplagt lige at se hvad der sker når \\(y_i\\) er henholdsvis 0 og 1 i udtrykket.\nDette udtryk benyttes når vi opskriver udtrykket for \\(L(a,b)\\) hvor vi desuden benytter notation produkt-notationen\n\\[ L(a,b)=\\prod_{i=1}^{n}(p(x_i)^{y_i}\\cdot (1-p(x_i))^{1-y_i}).\\]\nIstedet for at optimere ud fra \\(L(a,b)\\) kan vi optimere ud fra funktionen \\(ln(L(a,b))\\) som nu betegnes med \\(l(a,b)\\). Dette kan gøres da \\(ln(x)\\) er en voksende funktion.\nVed at benytte at \\(ln(a\\cdot b)=ln(a)+ln(b)\\) adskillige gange får vi at \\[l(a,b)=ln(L(a,b))=\\sum_{i=1}^{n}(ln(p(x_i)^{y_i})+ln((1-p(x_i))^{1-y_i})).\\]\nVed at benytte at \\(ln(a^k)=k\\cdot ln(a)\\) adskillige gange får vi at \\[ l(a,b)=\\sum_{i=1}^n ({y_i}\\cdot ln(p(x_i))+(1-y_i)\\cdot ln(1-p(x_i))).\\]\nVed at ophæve parentesen \\((1-y_i)\\) fås \\[ l(a,b)=\\sum_{i=1}^n ({y_i}\\cdot ln(p(x_i))+ln(1-p(x_i))- y_i\\cdot ln(1-p(x_i))).\\]\nI to af ledene indenfor sumtegnet har vi \\(y_i\\) som en faktor, og \\(y_i\\) sættes udenfor parentes \\[ l(a,b)=\\sum_{i}^n (ln(1-p(x_i))+{y_i}\\cdot (ln(p(x_i))-ln(1-p(x_i)))).\\] Ved hjælp af logaritme-regnereglen \\(ln(a/b)=ln(a)-ln(b)\\) får vi\n\\[ l(a,b)=\\sum_{i=1}^n \\left(ln(1-p(x_i))+y_i\\cdot ln\\left(\\frac{p(x_i)}{1-p(x_i)}\\right)\\right).\\]\nHer opsplitter vi til to summer hvor den ene ikke afhænger af \\(y_i\\). \\[ l(a,b)=\\sum_{i=1}^n ln(1-p(x_i))+\\sum_{i=1}^n y_i\\cdot ln\\left(\\frac{p(x_i)}{1-p(x_i)}\\right).\\]\nNu har vi fået styr over udtrykket for \\(l(a,b)\\) og vi har et udtryk for \\(p(x_i)\\) som dog afhænger af a og b.\nVed at kombinere ligningerne ??? får vi at\n\\[l(a,b)=\\sum_{i=1}^n ln\\left(1-\\frac{e^{a\\cdot x_i+ b}}{1+e^{a\\cdot x_i+b}}\\right)+\\sum_{i=1}^n y_i\\cdot (ax_i+b).\\] Udtrykket i logaritmen laves om til en samlet brøk\n\\[ l(a,b)=\\sum_{i=1}^n ln\\left(\\frac{1}{1+e^{a\\cdot x_i+b}}\\right)+\\sum_{i=1}^n y_i\\cdot (ax_i+b).\\] Her benytter vi igen regnereglen \\(ln(a-b)=ln(a)-ln(b)\\). \\[ l(a,b)=\\sum_{i=1}^n(ln(1)-ln(1+e^{a\\cdot x_i+b}))+\\sum_{i=1}^n y_i\\cdot (ax_i+b).\\] Da \\(ln(1)=0\\) har vi endelig \\[ l(a,b)=\\sum_{i=1}^n -ln(1+e^{a\\cdot x_i+b})+\\sum_{i=1}^n y_i\\cdot (ax_i+b).\\] Hvis man ser på bidraget fra \\(p_i(a,b)\\) bliver det til \\[ln(p_i(a,b))=y_i\\cdot \\ln(p(x_i))+ ({1-y_i})\\cdot \\ln(1-p(x_i)).\\]"
  },
  {
    "objectID": "log-reg.html#partiel-afledte-for-lab",
    "href": "log-reg.html#partiel-afledte-for-lab",
    "title": "Logistisk regression",
    "section": "Partiel afledte for l(a,b)",
    "text": "Partiel afledte for l(a,b)\nLad os først se på \\(\\frac{\\partial l(a,b)}{\\partial b}\\). Ved den første sum skal vi se udtrykket som en sammensat funktion hvor den indre funktion har et led som også er en sammensat funktion.\n\\[\\frac{\\partial l(a,b)}{\\partial b}= \\sum_{i=1}^n -\\frac{1}{1+e^{a\\cdot x_i+b}}\\cdot (0+e^{a\\cdot x_i+b})\\cdot(0+1) +\\sum_{i=1}^n y_i\\cdot (0+1).\\] Ved at reducere fås \\[\\frac{\\partial l(a,b)}{\\partial b}= \\sum_{i=1}^n -\\frac{e^{a\\cdot x_i+b}}{1+e^{a\\cdot x_i+b}} +\\sum_{i=1}^n y_i\\] Ved at bruge ligning ?? i forbindelse med den første sum og efterfølgende omskrive til en sum fås \\[\\frac{\\partial l(a,b)}{\\partial b}= \\sum_{i=1}^n -p(x_i) +\\sum_{i=1}^n y_i=\\sum_{i=1}^n (y_i-p(x_i)).\\]\nNu ser vi på \\(\\frac{\\partial l(a,b)}{\\partial a}\\). på tilsvarende måde. \\[\\frac{\\partial l(a,b)}{\\partial a}= \\sum_{i=1}^n -\\frac{1}{1+e^{a\\cdot x_i+b}}\\cdot (0+e^{a\\cdot x_i+b})\\cdot(1\\cdot x_i+0) +\\sum_{i=1}^n y_i\\cdot (1\\cdot x_i+0)\\] Der reduceres \\[\\frac{\\partial l(a,b)}{\\partial a}= \\sum_{i=1}^n -\\frac{e^{a\\cdot x_i+b}}{1+e^{a\\cdot x_i+b}}\\cdot x_i +\\sum_{i=1}^n y_i\\cdot x_i.\\]\nIgen bruges ligning ?? til at få\n\\[\\frac{\\partial l(a,b)}{\\partial a}= \\sum_{i=1}^n -p(x_i)\\cdot x_i +\\sum_{i=1}^n y_i\\cdot x_i=\\sum_{i=1}^n (y_i\\cdot x_i-p(x_i)\\cdot x_i).\\]\nEndelig kan \\(x_i\\) sættes udenfor parentes hvorved vi har \\[\\frac{\\partial l(a,b)}{\\partial b}=\\sum_{i=1}^n (y_i-p(x_i))\\cdot x_i.\\] For at lave optimering og finde minimum skal vi derved løse følgende to ligninger med to ubekendte \\[0=\\sum_{i=0}^n (y_i-p(x_i))\\cdot x_i \\quad \\text{og} \\quad 0=\\sum_{i=1}^n y_i-p(x_i).\\] Dette ligningssystem er dog ikke bare lige til at løse, så enten skal man igang med at benytte numeriske metoder til løsninger af dette eller benytte sig af gradient nedstigning (reference) for at få det optimale bud på parametrene \\(a\\) og \\(b\\) som fastlægger funktionen \\(p(x)\\)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Logistisk klassifikation/regression",
    "section": "",
    "text": "Logistisk klassifikation/regression\n\nLogistisk klassifikation\nLogistisk regression"
  },
  {
    "objectID": "logklas.html",
    "href": "logklas.html",
    "title": "Logistisk klassifikation",
    "section": "",
    "text": "Lad os forestille os at vi ønsker at se på hvor hurtigt det går før en befolkning får immunitet mod en sygdom. Her tænker vi at det er sådan, at få fra starten af har sygdom/immunitet med at der på et tidspunkt sker en kæmpe udvikling og alle med tiden bliver immune. For at få styr over udvikling kunne man for hver time der går tage en test af en tilfældig person og se om personen er imun eller ikke er imun. Derved får man et datasæt med punkter (x,y) hvor x er tid(dage) og y kunne være 0 svarende til ikke imun eller 1 svarende til imun. Her kunne man forestille sig et datasæt som plottet herunder.\n\n\n\nDatasæt hvor y=1 svarer til imun\n\n\nI stedet for at se på alle personer udtages nogen, og vi kunne være intereseret i på bagrund af datasættet at fastslå hvad sandsynligheden er for at man er imun på et givent tidspunkt. Dette kunne ses som en funktion \\(p(x)\\) som vi derved er interesseret i at få indsigt i. Det er desværre ikke helt så let, og vi bliver nød til at lave nogle antagelser inden vi kan komme med fornuftige forudsigelser.\nVi kunne starte med at se på om en lineær model ville fungere.\n\n\n\nDatasæt med lineær regression og s-formet-funktion\n\n\nDet er tydeligt at det ikke fungerer med en lineær funktion. (mere snak om hvorfor, her også fokus på problem med værdimængde som ikke er mellem 0 og 1).\nVed figuren er der også lagt en s-formet kurve ind med den egenskab at værdimængden er \\(]0,1[\\) som umiddelbart ser mere fornuftig ud.\nIstedet for at se på sandsynligheder direkte kan man se på to andre begreber, nemlig det som betegnes som “odds” som er forholdet mellem sandsynligheder for noget sker i forhold til sandsynligheden for det ikke sker, altså \\[\\frac{p(x)}{1-p(x)}.\\] (note : mere teori om odds)\nDesuden ses på den såkaldte logit-funktion som blot er den naturlige logaritme af odds, altså \\[ln\\left(\\frac{p(x)}{1-p(x)}\\right).\\] Hvis vi her ser dette som en funktion af \\(p(x)\\) med definitionsmængde mellem \\(0\\) og \\(1\\) (\\(p(x)\\) skal jo opfattes som sandsynlighed) ser vi at det giver følgende graf.\n Det er en voksende funktion som derved har en invers, som man kan vise er givet ved \\[\\frac{1}{1+e^{-y}}.\\] Her ses grafen for denne  Denne graf ser mere fornuftig ud i forhold til vores data og den model vi ønsker. Vi kan se at det passer fint med at værdimængden \\(]0,1[\\), men selvfølgelig skulle der være mulighed for justering af hvor hurtig væksten kommer til at blive og en form for vandret forskyd.\nHvis man har en funktion \\(f(x)\\) kan væksten speedes op med en faktor \\(k\\) ved at se på \\(f(k\\cdot x)\\). Hvis man f.eks. ønsker at forskyde med \\(h\\) i \\(x\\)-retningen kan det gøres med funktionen \\(f(k\\cdot (x-h)=f(k\\cdot x-k\\cdot h)\\). Her svarer \\(k\\cdot x-k\\cdot h\\) egentlig bare til en lineær funktion.\nDerved ville det give mening at benytte modellen \\[ln\\left(\\frac{p(x)}{1-p(x)}\\right)=a\\cdot x+b\\] som netop er den model der anvendes ved logistisk klassifikation.\n(evt. mere snak om funktionen \\(\\frac{1}{1+e^{-y}}.\\) : Sigmond og bedre koblinger mellem funktionerne så ideen er mere klar)"
  },
  {
    "objectID": "logklas.html#ideen-bag-logistisk-klassifikation",
    "href": "logklas.html#ideen-bag-logistisk-klassifikation",
    "title": "Logistisk klassifikation",
    "section": "",
    "text": "Lad os forestille os at vi ønsker at se på hvor hurtigt det går før en befolkning får immunitet mod en sygdom. Her tænker vi at det er sådan, at få fra starten af har sygdom/immunitet med at der på et tidspunkt sker en kæmpe udvikling og alle med tiden bliver immune. For at få styr over udvikling kunne man for hver time der går tage en test af en tilfældig person og se om personen er imun eller ikke er imun. Derved får man et datasæt med punkter (x,y) hvor x er tid(dage) og y kunne være 0 svarende til ikke imun eller 1 svarende til imun. Her kunne man forestille sig et datasæt som plottet herunder.\n\n\n\nDatasæt hvor y=1 svarer til imun\n\n\nI stedet for at se på alle personer udtages nogen, og vi kunne være intereseret i på bagrund af datasættet at fastslå hvad sandsynligheden er for at man er imun på et givent tidspunkt. Dette kunne ses som en funktion \\(p(x)\\) som vi derved er interesseret i at få indsigt i. Det er desværre ikke helt så let, og vi bliver nød til at lave nogle antagelser inden vi kan komme med fornuftige forudsigelser.\nVi kunne starte med at se på om en lineær model ville fungere.\n\n\n\nDatasæt med lineær regression og s-formet-funktion\n\n\nDet er tydeligt at det ikke fungerer med en lineær funktion. (mere snak om hvorfor, her også fokus på problem med værdimængde som ikke er mellem 0 og 1).\nVed figuren er der også lagt en s-formet kurve ind med den egenskab at værdimængden er \\(]0,1[\\) som umiddelbart ser mere fornuftig ud.\nIstedet for at se på sandsynligheder direkte kan man se på to andre begreber, nemlig det som betegnes som “odds” som er forholdet mellem sandsynligheder for noget sker i forhold til sandsynligheden for det ikke sker, altså \\[\\frac{p(x)}{1-p(x)}.\\] (note : mere teori om odds)\nDesuden ses på den såkaldte logit-funktion som blot er den naturlige logaritme af odds, altså \\[ln\\left(\\frac{p(x)}{1-p(x)}\\right).\\] Hvis vi her ser dette som en funktion af \\(p(x)\\) med definitionsmængde mellem \\(0\\) og \\(1\\) (\\(p(x)\\) skal jo opfattes som sandsynlighed) ser vi at det giver følgende graf.\n Det er en voksende funktion som derved har en invers, som man kan vise er givet ved \\[\\frac{1}{1+e^{-y}}.\\] Her ses grafen for denne  Denne graf ser mere fornuftig ud i forhold til vores data og den model vi ønsker. Vi kan se at det passer fint med at værdimængden \\(]0,1[\\), men selvfølgelig skulle der være mulighed for justering af hvor hurtig væksten kommer til at blive og en form for vandret forskyd.\nHvis man har en funktion \\(f(x)\\) kan væksten speedes op med en faktor \\(k\\) ved at se på \\(f(k\\cdot x)\\). Hvis man f.eks. ønsker at forskyde med \\(h\\) i \\(x\\)-retningen kan det gøres med funktionen \\(f(k\\cdot (x-h)=f(k\\cdot x-k\\cdot h)\\). Her svarer \\(k\\cdot x-k\\cdot h\\) egentlig bare til en lineær funktion.\nDerved ville det give mening at benytte modellen \\[ln\\left(\\frac{p(x)}{1-p(x)}\\right)=a\\cdot x+b\\] som netop er den model der anvendes ved logistisk klassifikation.\n(evt. mere snak om funktionen \\(\\frac{1}{1+e^{-y}}.\\) : Sigmond og bedre koblinger mellem funktionerne så ideen er mere klar)"
  },
  {
    "objectID": "logklas.html#funktionen-px",
    "href": "logklas.html#funktionen-px",
    "title": "Logistisk klassifikation",
    "section": "Funktionen \\(p(x)\\)",
    "text": "Funktionen \\(p(x)\\)\nVi ved nu at vi arbejder med følgende model \\[ln\\left( \\frac{p(x)}{1-p(x)}\\right) =a\\cdot x+b\\]\nLad os se på hvordan man får et udtryk for \\(p(x)\\). Vi starter med at skifte fortegn på begge sider af lighedstegnet. \\[-ln\\left( \\frac{p(x)}{1-p(x)}\\right) =-a\\cdot x-b.\\] Ved at benytte regnereglen \\(ln(a/b)=ln(a)-ln(b)\\) frem og tilbage på venstresiden sammen med fortegnet fås \\[ln\\left( \\frac{1-p(x)}{p(x)}\\right) =-a\\cdot x-b.\\]\nVed at benytte at \\(e^x\\) er invers til \\(ln(x)\\) fås at \\[\\frac{1-p(x)}{p(x)} =e^{-a\\cdot x-b}\\] Her kan brøken deles op \\[\\frac{1}{p(x)}-1 =e^{-a\\cdot x-b}\\] Her kan vi efter at have adderet med \\(1\\) få isoleret \\(p(x)\\) ved at gange med p(x) og efter følgende dividere med \\(e^{-a\\cdot x-b}\\) hvorved vi ender ud med at \\[{p(x)} =\\frac{1}{1+e^{-a\\cdot x-b}}.\\]\nHvis vi forlænger med \\(e^{a\\cdot x+b}\\) kan \\(p(x)\\) også skrives som \\[{p(x)} =\\frac{e^{a\\cdot xb}}{1+e^{a\\cdot x+b}}.\\]"
  },
  {
    "objectID": "logklas.html#maksimum-likelihood",
    "href": "logklas.html#maksimum-likelihood",
    "title": "Logistisk klassifikation",
    "section": "Maksimum Likelihood",
    "text": "Maksimum Likelihood\nLad os starte med at forstille os at vi allerede kender funktionen \\(p(x)\\). Derved kan vi beregne sandsynligheden for at vi får de givne observationer. Det \\(i\\)’te punkt fra datasættet betegnes med \\((x_i,y_i)\\) og antallet af observationer betegnes med \\(n\\). For en observation \\((x_i,y_i)\\) kender vi tidspunktet(svarende til \\(x\\)-værdien) men \\(y\\)-værdien afhænger af den tilfældigt udvalgte person. Sandsynligheden for at \\(y\\)-værdien antager værdien \\(1\\) er \\(p(x)\\). Derved ved vi også at sandsynlighden for at \\(y\\)-værdien antager værdien \\(0\\) er \\(1-p(x)\\).\nVi antager at der er uafhængighed mellem vores observationerne hvorved sandsynligheder kan ganges sammen. Dette kan skrives ved hjælp af produkt-tegnet hvor vi ved det ene produkt indikerer at vi kun skal benytte de observationer hvor \\(y_i=1\\) og ved den anden kun skal benytte dem hvor \\(y_i=0\\). Vi får følgende sandsynliged, her betegnet med \\(L\\), hørende til vores datasæt \\[ L=\\prod_{i : y_{i}=1} p(x_i)\\cdot \\prod_{i : y_{i}=0} (1-p(x_i)).\\] (note med læsning af \\(i:y_i=1\\)).\nVed en model skal det selvfølgelig være sådan at den er tilpasset sådan at dette udtryk er størst muligt da modellen derved forudsiger at det observerede datasæt er mest sandsynligt.\nIstedet for at se på netop dette udtryk tages \\(ln\\) af udtrykket. Ved at benytte at \\(ln(a\\cdot b)=ln(a)+ln(b)\\) adskillige gange får vi at \\[ln(L)=\\sum_{i : y_{i}=1} ln(p(x_i))+\\sum_{i : y_{i}=0} ln(1-p(x_i))\\] Da funktion \\(f(x)=ln(x)\\) er en voksende funktion, vil en optimering af \\(ln(L)\\) og \\(L\\) være det samme.\nNu ønsker vi egentlig at få udtrykyt \\(L\\) hvor vi kun benytter en sum istedet for to. Til dette indser vi lige at \\[\n\\begin{array}{cc}\n  p(x_i)^{y_i}= &  \n    \\begin{array}{cc}\n      1 & hvis\\quad  y_i= 0 \\\\\n      p(x_i) & hvis\\quad  y_i= 1\n    \\end{array}\n\\end{array}\n\\] og \\[\n\\begin{array}{cc}\n  (1-p(x_i))^{1-y_i}= &  \n    \\begin{array}{cc}\n      (1-p(x_i)) & hvis\\quad  y_i= 0 \\\\\n      1 & hvis\\quad  y_i= 1\n    \\end{array}\n\\end{array}\n\\] Ved et produkt med flere faktorer har en faktor \\(1\\) selvfølgelig ikke nogen betydning, og vi får at \\(L\\) kan skrives som \\[ L=\\prod_{i}^n p(x_i)^{y_i}\\cdot (1-p(x_i))^{1-y_i}.\\] Ved at benytte at \\(ln(a\\cdot b)=ln(a)+ln(b)\\) og \\(ln(a^k)=k\\cdot ln(a)\\) adskillige gange får vi at \\[ ln(L)=\\sum_{i=1}^n {y_i}\\cdot ln(p(x_i))+(1-y_i)\\cdot ln(1-p(x_i)).\\] Ved at ophæve parentesen fås \\[ ln(L)=\\sum_{i=1}^n {y_i}\\cdot ln(p(x_i))+ln(1-p(x_i))- y_i\\cdot ln(1-p(x_i)).\\]\nI to af ledene indenfor sumtegnet har vi \\(y_i\\) som en faktor, og \\(y_i\\) sættes udenfor parentes \\[ ln(L)=\\sum_{i}^n ln(1-p(x_i))+{y_i}\\cdot (ln(p(x_i))-ln(1-p(x_i))).\\] Ved hjælp af logaritme-regnereglen \\(ln(a/b)=ln(a)-ln(b)\\) får vi\n\\[ ln(L)=\\sum_{i=1}^n ln(1-p(x_i))+y_i\\cdot ln\\left(\\frac{p(x_i)}{1-p(x_i)}\\right).\\]\nHer opsplitter vi til to summer hvor den ene ikke afhænger af \\(y_i\\). \\[ ln(L)=\\sum_{i=1}^n ln(1-p(x_i))+\\sum_{i=1} y_i\\cdot ln\\left(\\frac{p(x_i)}{1-p(x_i)}\\right).\\]"
  },
  {
    "objectID": "logklas.html#maksimum-likelihood-med-valgt-px",
    "href": "logklas.html#maksimum-likelihood-med-valgt-px",
    "title": "Logistisk klassifikation",
    "section": "Maksimum Likelihood med valgt \\(p(x)\\)",
    "text": "Maksimum Likelihood med valgt \\(p(x)\\)\nNu har vi fået styr over udtrykket for likelihood, og vi har fundet et udtryk for \\(p(x)\\) ved den valgte model. Dog afhænger \\(p(x)\\) stadigvæk af valget af \\(a\\) og \\(b\\) hvorved \\(L\\) også kommer til at afhænge deraf, og vil derfor noteres som \\(L(a,b)\\) i det følgende.\nVed at kombinere ligningerne ??? får vi at\n\\[ ln(L(a,b))=\\sum_{i=1}^n ln\\left(1-\\frac{e^{a\\cdot x_i+ b}}{1+e^{a\\cdot x_i+b}}\\right)+\\sum_{i=1} y_i\\cdot (ax_i+b).\\] Udtrykket i logaritmen laves om til en samlet brøk\n\\[ ln(L(a,b))=\\sum_{i=1}^n ln\\left(\\frac{1}{1+e^{a\\cdot x_i+b}}\\right)+\\sum_{i=1} y_i\\cdot (ax_i+b).\\] Her benytter vi igen regnereglen \\(ln(a-b)=ln(a)-ln(b)\\). \\[ ln(L(a,b))=\\sum_{i=1}^n ln(1)-ln(1+e^{a\\cdot x_i+b})+\\sum_{i=1} y_i\\cdot (ax_i+b).\\] Da \\(ln(1)=0\\) har vi endelig \\[ ln(L(a,b))=\\sum_{i=1}^n -ln(1+e^{a\\cdot x_i+b})+\\sum_{i=1} y_i\\cdot (ax_i+b).\\]"
  },
  {
    "objectID": "logklas.html#optimering",
    "href": "logklas.html#optimering",
    "title": "Logistisk klassifikation",
    "section": "Optimering",
    "text": "Optimering\nFor at finde et minimum for \\(L(a,b)\\) eller \\(ln(L(a,b))\\) kan vi selffølgelige finde stationære punkter ved at sætte de partiel afledte lig \\(0\\).\nLad os først se på \\(\\frac{\\partial l(a,b)}{\\partial b}\\). Ved den første skal vi se udtrykket som en sammensat funktion hvor den indre funktion har et led som også er en sammensat funktion.\n\\[\\frac{\\partial l(a,b)}{\\partial b}= \\sum_{i=1}^n -\\frac{1}{1+e^{a\\cdot x_i+b}}\\cdot (0+e^{a\\cdot x_i+b})\\cdot(0\\cdot x_i+1)) +\\sum_{i=1} y_i\\cdot (1\\cdot 0+1)\\] Ved at reducere fås \\[\\frac{\\partial l(a,b)}{\\partial b}= \\sum_{i=1}^n -\\frac{e^{a\\cdot x_i+b}}{1+e^{a\\cdot x_i+b}} +\\sum_{i=1} y_i\\] Ved at bruge ligning ?? i forbindelse med den første sum kan dette omskrives til \\[\\frac{\\partial l(a,b)}{\\partial b}= \\sum_{i=1}^n -p(x_i) +\\sum_{i=1} y_i=\\sum_{i=1}^n y_i-p(x_i).\\]\nNu ser vi på \\(\\frac{\\partial l(a,b)}{\\partial a}\\). på tilsvarende måde. \\[\\frac{\\partial l(a,b)}{\\partial b}= \\sum_{i=1}^n -\\frac{1}{1+e^{a\\cdot x_i+b}}\\cdot (0+e^{a\\cdot x_i+b})\\cdot(1\\cdot x_i+0)) +\\sum_{i=1} y_i\\cdot (1\\cdot x_i+0)\\] Der reduceres \\[\\frac{\\partial l(a,b)}{\\partial b}= \\sum_{i=1}^n -\\frac{e^{a\\cdot x_i+b}}{1+e^{a\\cdot x_i+b}}\\cdot x_i +\\sum_{i=1} y_i\\cdot x_i.\\]\nIgen bruges ligning ?? til at få\n\\[\\frac{\\partial l(a,b)}{\\partial b}= \\sum_{i=1}^n -p(x_i)\\cdot x_i +\\sum_{i=1} y_i\\cdot x_i=\\sum_{i=0}^n y_i\\cdot x_i-p(x_i)\\cdot x_i.\\]\nEndelig kan \\(x_i\\) sættes udenfor parentes hvorved vi har \\[\\frac{\\partial l(a,b)}{\\partial b}=\\sum_{i=0}^n (y_i-p(x_i))\\cdot x_i.\\] For at lave optimering og finde minimum skal vi derved løse følgende to ligninger med to ubekendte \\[0=\\sum_{i=0}^n (y_i-p(x_i))\\cdot x_i \\quad \\text{og} \\quad 0=\\sum_{i=1}^n y_i-p(x_i).\\] Dette ligningssystem er dog ikke bare lige til at løse, så enten skal man igang med at benytte numeriske metoder til løsninger af dette eller benytte sig af gradient nedstigning (reference) for at få det optimale bund på parametrene \\(a\\) og \\(b\\) som fastlægger funktionen \\(p(x)\\)."
  },
  {
    "objectID": "logklas.html#prediktion-og-relation-til-logistisk-udvikling",
    "href": "logklas.html#prediktion-og-relation-til-logistisk-udvikling",
    "title": "Logistisk klassifikation",
    "section": "Prediktion og Relation til logistisk udvikling",
    "text": "Prediktion og Relation til logistisk udvikling\nNår man endelig har fået fastlagt parametrene \\(a\\) og \\(b\\) kan vi endelig få vores model \\(p(x)\\) ud fra.\n(mabgler alt med prædiktion og om man skal forudsige \\(y=1\\) eller \\(y=0\\))\nMan kan selvfølgelig tænke over om ovenstående skulle have relation til logistisk vækst. Hvis man fra logistisk klassifikation kommer frem til funktionen \\(p(x)\\) \\[{p(x)} =\\frac{1}{1+e^{-a\\cdot x-b}}.\\] Vi husker at det var denne funktionen som forudsiger sandsynligheden for \\(y=1\\).\nSå f.eks. ved eksemplet med imun/ikke imun kan man forudsige hvad sandsynligheden er for at en tilfældig person er imun efter 100 dage ved at beregne\n\\[{p(100)} =\\frac{1}{1+e^{-a\\cdot 100-b}}.\\]\nDet kan selvfølgelig være at man ikke er interesseret i en person men istedte ønsker et bud på hvor mange der faktisk er imune blandt hele befolkningen med \\(M\\) personer. Hvis \\(f(x)\\) er antal imune efter \\(x\\) dage må det være oplagt at benytte modellen\n\\[f(x)=M\\cdot p(x)=\\frac{M}{1+e^{-a\\cdot x-b}}.\\] Ved \\(a\\) kan vi lige gange og dividere med \\(M\\) og kalde \\(a/M\\) for \\(a_{ny}\\). Derved er \\[f(x)=M\\cdot p(x)=\\frac{M}{1+e^{-M\\cdot a_{ny}\\cdot x-b}}=\\frac{M}{1+e^{-M\\cdot a_{ny}\\cdot x-b}}.\\] Ved at benytte potensregneregel får vi \\[f(x)=M\\cdot p(x)=\\frac{M}{1+e^{-M\\cdot a_{ny}\\cdot x-b}}=\\frac{M}{1+e^{-b}\\cdot e^{-M\\cdot a_{ny}\\cdot x}}.\\] Hvis vi kalder \\(e^{-b}\\) for \\(c\\) får vi \\[f(x)=M\\cdot p(x)=\\frac{M}{1+e^{-M\\cdot a_{ny}\\cdot x-b}}=\\frac{M}{1+c\\cdot e^{-M\\cdot a_{ny}\\cdot x}}.\\] Som netop svarer til den kendte formel hørende til logistisk vækst og løsningen af differentialligningen \\[y'=a\\cdot y\\cdot(M-y)\\]."
  }
]